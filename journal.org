# -*- mode: org; fill-column: 78; -*-
# Time-stamp: <2023-07-05 20:28:18 krylon>
#
#+TAGS: optimize(o) refactor(r) bug(b) feature(f) architecture(a)
#+TAGS: web(w) database(d) javascript(j) ui(u)
#+TODO: TODO(t) IMPLEMENT(i) TEST(e) RESEARCH(r) | DONE(d)
#+TODO: MEDITATE(m) PLANNING(p) REFINE(n) | FAILED(f) CANCELLED(c) SUSPENDED(s)
#+TODO: EXPERIMENT(x) |
#+PRIORITIES: A G D

* jobq
  jobq is a spooler and queue for batch jobs.
  I will try to keep it simple at first, but I have some ideas for nifty
  features I hope to implement along the way.

  JOBQ IS A VERY UNCREATIVE NAME. I WOULD REALLY LIKE SOMETHING BETTER, BUT I
  NEEDED A NAME TO GET STARTED. I HOPE I'LL FIND A BETTER NAME EVENTUALLY.
** Clocktable
   #+BEGIN: clocktable :scope file :maxlevel 20
   #+CAPTION: Clock summary at [2023-07-05 Mi 20:28]
   | Headline                 | Time      |         |       |       |
   |--------------------------+-----------+---------+-------+-------|
   | *Total time*             | *1d 3:55* |         |       |       |
   |--------------------------+-----------+---------+-------+-------|
   | jobq                     | 1d 3:55   |         |       |       |
   | \_  Features [0/6]       |           |    0:29 |       |       |
   | \_    Enqueue jobs [0/2] |           |         |  0:09 |       |
   | \_      Scheduling       |           |         |       |  0:09 |
   | \_  Components [0/1]     |           | 1d 3:26 |       |       |
   | \_    Database [0/0]     |           |         | 11:32 |       |
   | \_    Data types [0/2]   |           |         | 15:54 |       |
   | \_      Job              |           |         |       |  5:13 |
   | \_      Queue [0/1]      |           |         |       | 10:41 |
   #+END:
** Journal
   Here I write mainly chronologically.
*** [2023-06-19 Mo 20:28]
    I should write some tests for the queueing stuff before I move on.
** Features [0/6]                                                   :feature:
   :PROPERTIES:
   :COOKIE_DATA: todo recursive
   :VISIBILITY: children
   :END:
   :LOGBOOK:
   CLOCK: [2023-06-18 So 15:40]--[2023-06-18 So 16:00] =>  0:20
   :END:
*** TODO Enqueue jobs [0/2]
    Obviously. When submitted, a job is not executed right away, but added to
    a queue. When ready, the job scheduler/monitor will remove the first one
    from the queue and run it. And then the next one.
**** RESEARCH Scheduling
     :LOGBOOK:
     CLOCK: [2023-06-18 So 16:05]--[2023-06-18 So 16:14] =>  0:09
     :END:
     Would be nice if I could also submit a job and define it should be
     started at a given time.
     Also, I would like to be able to restrict how long a job runs and
     terminate it if it exceeds its time.
     Also, it would be extra nice, if I could state a job should be run not at
     a given time, but in a given time window, e.g. between 20:00 and
     08:00. The scheduler then should juggle the various jobs it should run so
     they all meet their time window.

     [2023-06-18 So 16:06]
     I consulted awesome-go and found a number of job scheduling
     libraries. Most seem to be aimed at cron-like scenarios, but some are
     more flexible/general. I'll look into those.
     Even if I end up not using any of these, I can take some ideas, maybe
     learn a few tricks.

     In the very long run, adding cron-like functionality for recurring jobs
     seems desirable as well.
***** quartz https://github.com/reugn/go-quartz
***** cdule https://github.com/deepaksinghvi/cdule
      Uses a database for persistence (optinally sqlite in-memory), which
      sounds nice.
***** tasks https://github.com/madflojo/tasks
      Sounds more like a cron-like scheduler, but I'll put it on my list.
**** MEDITATE [#F] Pipelines
     It would be kind of nice if I could support something equivalent to shell
     pipelines. /Possibly/ even something more complex, like having a sequence
     of commands running as a job instead of a single command.
*** TODO Spool output
    Like ts, my main inspiration, I want to capture the output of running jobs
    and save it to files.
    I also want to, optionally at least, compress the output.
**** Compression
     In the long run, I want to support multiple compression formats, or at
     least do some experimenting/benchmarking with various compression
     algorithms.
     The Go standard library provides support for gzip.
     - https://github.com/klauspost/compress provides a few more
     - https://github.com/ulikunitz/xz provides support for xz, but the README
       says it should not be considered stable.
     To get started, I'll just support gzip initially, because that is part of
     Go's standard library, but I'll implement it in such a way that adding
     support for further compression methods later on becomes as easy as
     possible.
*** TODO Parallel
    I want to be able to - optionally - run multiple jobs in parallel.
*** TODO Multiple queues
    I want to be able to support multiple different queues simultaneously,
    e.g. one queue for downloading files, one for compressing videos, and so
    forth.
*** Moonshot ideas
    Some goals are more of the speculative, wishful thinking kind. I have no
    immediate intention of implementing these. But maybe, some day the program
    works to my satisfaction, and I find myself with enough time and nothing
    better to do. A guy can dream, can't he?
    - Web interface
    - Networking
      At that point we'd be be leaving the "simple job queue/scheduler"
      territory and entering cluster manager land. It would be interesting to
      do.
      But it would also be interesting - and more realistic - to monitor job
      queues on multiple machines. If I have a dedicated queue for
      e.g. downloading files, I might /move/ that queue around, have it "live"
      on my desktop computer in the daytime, then move it to my home server at
      night. That would be very difficult to get right, but it sounds
      alluring, doesn't it?
** Planning [0/0]                                              :architecture:
   :PROPERTIES:
   :COOKIE_DATA: todo recursive
   :VISIBILITY: children
   :END:
   [2023-06-19 Mo 17:31]
   My short-term plan is as follows:
   First, I want to get to the point where I can just add jobs and run them.
   My next step would be to add persistence to the queue.
   After that, I would like to round the existing features up by a nice CLI.
** Components [0/1]
   :PROPERTIES:
   :COOKIE_DATA: todo recursive
   :VISIBILITY: children
   :END:
*** Database [0/0]
    :PROPERTIES:
    :COOKIE_DATA: todo recursive
    :VISIBILITY: children
    :END:
    :LOGBOOK:
    CLOCK: [2023-07-05 Mi 19:39]--[2023-07-05 Mi 20:28] =>  0:49
    CLOCK: [2023-07-04 Di 19:19]--[2023-07-04 Di 21:35] =>  2:16
    CLOCK: [2023-07-04 Di 18:26]--[2023-07-04 Di 19:04] =>  0:38
    CLOCK: [2023-07-03 Mo 18:30]--[2023-07-03 Mo 21:46] =>  3:16
    CLOCK: [2023-07-03 Mo 18:13]--[2023-07-03 Mo 18:22] =>  0:09
    CLOCK: [2023-07-01 Sa 19:40]--[2023-07-01 Sa 22:05] =>  2:25
    CLOCK: [2023-07-01 Sa 17:40]--[2023-07-01 Sa 19:39] =>  1:59
    :END:
    I'll just roll with SQLite, no experiments. Unless somebody builds an
    SQLite-like library that operates on JSON or CSV files, it is just too
    convenient to even seriously consider alternatives.
    However, I might consider using something ORM-like to avoid writing such
    endless masses of boilerplate code.
    [2023-07-01 Sa 19:24] So, gorm appears to have an API I find aesthetically
    unpleasant. I'll skip. But I'm looking at GoSQL next, which at first
    glance looks more pleasant to use.
    [2023-07-03 Mo 18:12] Nah, GoSQL wasn't my cup of tea either. I'll just go
    with my usual approach, maybe I can find a way to make it a little bit
    more elegant.
    
*** Data types [0/2]
    :PROPERTIES:
    :COOKIE_DATA: todo recursive
    :VISIBILITY: children
    :END:
**** TODO Job
     :LOGBOOK:
     CLOCK: [2023-06-18 So 21:35]--[2023-06-18 So 22:40] =>  1:05
     CLOCK: [2023-06-18 So 16:29]--[2023-06-18 So 20:37] =>  4:08
     :END:
     Clearly, I should start here. What properties of a Job do I need. Also,
     how do I run a job, handle output and so forth.

     It would be nice if I could support pipelines, like a shell script. I
     could go cheap and just make it a shell script and then run the shell,
     but ... it doesn't feel right, does it?
**** TODO Queue [0/1]
     :PROPERTIES:
     :COOKIE_DATA: todo recursive
     :VISIBILITY: children
     :END:
     :LOGBOOK:
     CLOCK: [2023-07-01 Sa 17:36]--[2023-07-01 Sa 17:38] =>  0:02
     CLOCK: [2023-06-30 Fr 17:23]--[2023-06-30 Fr 20:48] =>  3:25
     CLOCK: [2023-06-29 Do 17:57]--[2023-06-29 Do 18:25] =>  0:28
     CLOCK: [2023-06-29 Do 15:34]--[2023-06-29 Do 16:43] =>  1:09
     CLOCK: [2023-06-20 Di 03:45]--[2023-06-20 Di 05:29] =>  1:44
     CLOCK: [2023-06-19 Mo 19:01]--[2023-06-19 Mo 20:29] =>  1:28
     CLOCK: [2023-06-19 Mo 17:38]--[2023-06-19 Mo 18:03] =>  0:25
     CLOCK: [2023-06-19 Mo 12:43]--[2023-06-19 Mo 14:43] =>  2:00
     :END:
     I should start thinking about persistence. That would be nice,
     actually. Keep a history, and survive crashes more gracefully.

     I split the functionality, the actual, CS textbook queue is _queue.fifo_,
     the /Job/ Queue the rest of the program interfaces with uses that data
     structure but adds some functionality. It's unfortunate, perhaps, that
     both the basic data structure and the Job monitor are called "queue". 
***** TODO Persistence                                              :feature:
      It would be nice if I could persist the queue to disk in some way, so I
      can recover it after a crash and e.g. still associate spool files with a
      Job.
      I am not sure how I exactly I'll do that. SQLite surely would be up to
      the task, but I end up using it practically in all my projects, and I
      would like to use something else for once. Maybe bolt or BuntDB? Maybe
      something else entirely. The possibilities are endless, but I don't want
      to waste too much time on exploring obscure alternatives.

      [2023-07-01 Sa 17:36]
      After having a very early, primitive version of the Queue working, I
      realized I actually need to have *some* kind of persistence for
      information about finished or failed jobs.
      So here we go. Instead of an in-memory queue, I can just put everything
      in a database and have that be my queue.
** Bugs
